"""
è§†é¢‘é™æ€å¸§è£å‰ªå·¥å…·

è‡ªåŠ¨æ£€æµ‹è§†é¢‘ä¸­çš„è¿åŠ¨ç‰‡æ®µï¼Œç§»é™¤é™æ€ç­‰å¾…éƒ¨åˆ†ã€‚
ä½¿ç”¨ OpenCV Frame Difference + FFmpeg å¿«é€Ÿåˆ‡å‰²ã€‚

ç”¨æ³•:
    python scripts/trim_static_frames.py input.mp4
    python scripts/trim_static_frames.py input.mp4 -o output.mp4
    python scripts/trim_static_frames.py input.mp4 --threshold 8.0
"""
import cv2
import numpy as np
import subprocess
import tempfile
import os
import sys
from pathlib import Path
from typing import List, Tuple, Optional


def log(message: str) -> None:
    """æ‰“å°æ—¥å¿—"""
    print(message, flush=True)


def adaptive_threshold(video_path: str, percentile: float = 75) -> float:
    """
    æ ¹æ®è§†é¢‘æ•´ä½“å·®å¼‚åˆ†å¸ƒè‡ªåŠ¨ç¡®å®šé˜ˆå€¼

    Args:
        video_path: è§†é¢‘è·¯å¾„
        percentile: ç™¾åˆ†ä½æ•°ï¼ˆå»ºè®® 70-80ï¼‰

    Returns:
        è‡ªé€‚åº”é˜ˆå€¼
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

    diffs = []
    prev_frame = None

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        if prev_frame is not None:
            diff = cv2.absdiff(prev_frame, gray)
            diffs.append(np.mean(diff))

        prev_frame = gray

    cap.release()

    if not diffs:
        return 5.0

    threshold = np.percentile(diffs, percentile)
    return max(threshold, 3.0)


def detect_motion_segments(
    video_path: str,
    threshold: float,
    min_motion_duration: float = 0.3
) -> Tuple[List[Tuple[float, float]], float]:
    """
    æ£€æµ‹è§†é¢‘ä¸­çš„è¿åŠ¨ç‰‡æ®µ

    Args:
        video_path: è§†é¢‘è·¯å¾„
        threshold: å¸§å·®å¼‚é˜ˆå€¼ï¼ˆ0-255ï¼‰
        min_motion_duration: æœ€å°è¿åŠ¨æ—¶é•¿ï¼ˆç§’ï¼‰

    Returns:
        (segments, fps) - è¿åŠ¨ç‰‡æ®µæ—¶é—´æˆ³åˆ—è¡¨å’Œå¸§ç‡
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    prev_frame = None
    motion_flags = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        if prev_frame is not None:
            diff = cv2.absdiff(prev_frame, gray)
            mean_diff = np.mean(diff)
            motion_flags.append(mean_diff > threshold)

        prev_frame = gray

    cap.release()

    # åˆå¹¶è¿ç»­è¿åŠ¨å¸§ä¸ºæ—¶é—´æ®µ
    segments = []
    in_motion = False
    start_frame = 0
    min_frames = int(min_motion_duration * fps)

    for i, is_motion in enumerate(motion_flags):
        if is_motion and not in_motion:
            start_frame = i
            in_motion = True
        elif not is_motion and in_motion:
            if i - start_frame >= min_frames:
                segments.append((start_frame / fps, i / fps))
            in_motion = False

    if in_motion and len(motion_flags) - start_frame >= min_frames:
        segments.append((start_frame / fps, len(motion_flags) / fps))

    return segments, fps


def merge_segments(segments: List[Tuple[float, float]], max_gap: float = 0.3) -> List[Tuple[float, float]]:
    """
    åˆå¹¶é—´éš”å°äº max_gap ç§’çš„ç‰‡æ®µ

    Args:
        segments: æ—¶é—´æ®µåˆ—è¡¨ [(start, end), ...]
        max_gap: æœ€å¤§é—´éš”ï¼ˆç§’ï¼‰

    Returns:
        åˆå¹¶åçš„æ—¶é—´æ®µåˆ—è¡¨
    """
    if not segments:
        return []

    merged = [segments[0]]
    for start, end in segments[1:]:
        last_start, last_end = merged[-1]
        if start - last_end <= max_gap:
            merged[-1] = (last_start, end)
        else:
            merged.append((start, end))

    return merged


def add_buffer(
    segments: List[Tuple[float, float]],
    buffer: float = 0.2,
    video_duration: Optional[float] = None
) -> List[Tuple[float, float]]:
    """
    åœ¨è¿åŠ¨ç‰‡æ®µå‰åå„åŠ  buffer ç§’

    Args:
        segments: æ—¶é—´æ®µåˆ—è¡¨
        buffer: ç¼“å†²æ—¶é—´ï¼ˆç§’ï¼‰
        video_duration: è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰

    Returns:
        æ·»åŠ ç¼“å†²åçš„æ—¶é—´æ®µåˆ—è¡¨
    """
    buffered = []
    for start, end in segments:
        new_start = max(0, start - buffer)
        new_end = end + buffer
        if video_duration:
            new_end = min(video_duration, new_end)
        buffered.append((new_start, new_end))

    return buffered


def extract_segments(
    video_path: str,
    segments: List[Tuple[float, float]],
    output_path: str
) -> None:
    """
    ä½¿ç”¨ FFmpeg æå–è¿åŠ¨ç‰‡æ®µå¹¶æ‹¼æ¥

    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        segments: æ—¶é—´æ®µåˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    if not segments:
        raise ValueError("æ²¡æœ‰æ£€æµ‹åˆ°è¿åŠ¨ç‰‡æ®µ")

    if len(segments) == 1:
        start, end = segments[0]
        subprocess.run([
            "ffmpeg", "-y", "-i", video_path,
            "-ss", str(start), "-to", str(end),
            "-c", "copy",
            output_path
        ], check=True, capture_output=True)
        return

    with tempfile.TemporaryDirectory() as tmpdir:
        segment_paths = []
        concat_file = os.path.join(tmpdir, "segments.txt")

        for i, (start, end) in enumerate(segments):
            segment_path = os.path.join(tmpdir, f"segment_{i}.mp4")
            subprocess.run([
                "ffmpeg", "-y", "-i", video_path,
                "-ss", str(start), "-to", str(end),
                "-c", "copy",
                segment_path
            ], check=True, capture_output=True)
            segment_paths.append(segment_path)

        with open(concat_file, "w") as f:
            for path in segment_paths:
                f.write(f"file '{path}'\n")

        subprocess.run([
            "ffmpeg", "-y", "-f", "concat", "-safe", "0",
            "-i", concat_file,
            "-c", "copy",
            output_path
        ], check=True, capture_output=True)


def get_video_duration(video_path: str) -> float:
    """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
    fps = cap.get(cv2.CAP_PROP_FPS)
    cap.release()

    return frame_count / fps if fps > 0 else 0


def trim_video(
    input_path: str,
    output_path: Optional[str] = None,
    threshold: Optional[float] = None,
    min_motion_duration: float = 0.3,
    merge_gap: float = 0.3,
    buffer: float = 0.2,
    verbose: bool = True
) -> str:
    """
    è‡ªåŠ¨è£å‰ªè§†é¢‘ä¸­çš„é™æ€å¸§ï¼Œåªä¿ç•™è¿åŠ¨ç‰‡æ®µ

    Args:
        input_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆNone = è‡ªåŠ¨ç”Ÿæˆ .trimmed.mp4ï¼‰
        threshold: å¸§å·®å¼‚é˜ˆå€¼ï¼ˆNone = è‡ªåŠ¨æ£€æµ‹ï¼‰
        min_motion_duration: æœ€å°è¿åŠ¨æ—¶é•¿ï¼ˆç§’ï¼‰
        merge_gap: åˆå¹¶é—´éš”ï¼ˆç§’ï¼‰
        buffer: ç¼“å†²æ—¶é—´ï¼ˆç§’ï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—

    Returns:
        è£å‰ªåçš„è§†é¢‘è·¯å¾„ï¼ˆå¦‚æœæ— éœ€è£å‰ªåˆ™è¿”å›åŸè·¯å¾„ï¼‰
    """
    input_path = str(Path(input_path).resolve())

    if not os.path.exists(input_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

    if output_path is None:
        output_path = str(Path(input_path).with_suffix('')) + '.trimmed.mp4'

    if verbose:
        log(f"ğŸ¬ è£å‰ªè§†é¢‘é™æ€å¸§: {Path(input_path).name}")

    # 1. è·å–è§†é¢‘æ—¶é•¿
    duration = get_video_duration(input_path)

    # 2. è‡ªåŠ¨æ£€æµ‹é˜ˆå€¼
    if threshold is None:
        threshold = adaptive_threshold(input_path)
        if verbose:
            log(f"   è‡ªåŠ¨é˜ˆå€¼: {threshold:.2f}")

    # 3. æ£€æµ‹è¿åŠ¨ç‰‡æ®µ
    segments, _ = detect_motion_segments(input_path, threshold, min_motion_duration)

    if not segments:
        if verbose:
            log(f"   âš ï¸  æœªæ£€æµ‹åˆ°è¿åŠ¨ç‰‡æ®µï¼Œä¿ç•™åŸè§†é¢‘")
        return input_path

    # 4. åˆå¹¶ç›¸é‚»ç‰‡æ®µ
    segments = merge_segments(segments, merge_gap)

    # 5. æ·»åŠ ç¼“å†²
    segments = add_buffer(segments, buffer, duration)

    # 6. æ£€æŸ¥æ˜¯å¦éœ€è¦è£å‰ª
    total_motion = sum(end - start for start, end in segments)
    coverage = total_motion / duration if duration > 0 else 0

    if coverage >= 0.95:
        if verbose:
            log(f"   â„¹ï¸  è§†é¢‘å¤§éƒ¨åˆ†æ˜¯è¿åŠ¨ ({coverage*100:.1f}%)ï¼Œè·³è¿‡è£å‰ª")
        return input_path

    # 7. æ‰“å°ç‰‡æ®µä¿¡æ¯
    if verbose:
        log(f"   æ£€æµ‹åˆ° {len(segments)} ä¸ªè¿åŠ¨ç‰‡æ®µ:")
        for i, (start, end) in enumerate(segments, 1):
            log(f"     ç‰‡æ®µ {i}: {start:.2f}s - {end:.2f}s ({end-start:.2f}s)")

        reduction = (1 - total_motion / duration) * 100 if duration > 0 else 0
        log(f"   åŸå§‹: {duration:.1f}s â†’ è£å‰ªå: {total_motion:.1f}s (å‡å°‘ {reduction:.0f}%)")

    # 8. æå–å¹¶æ‹¼æ¥
    try:
        extract_segments(input_path, segments, output_path)
        if verbose:
            log(f"   âœ“ ä¿å­˜è‡³: {Path(output_path).name}")
        return output_path
    except subprocess.CalledProcessError as e:
        if verbose:
            log(f"   âŒ FFmpeg é”™è¯¯: {e.stderr.decode() if e.stderr else str(e)}")
        raise
    except Exception as e:
        if verbose:
            log(f"   âŒ è£å‰ªå¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨è£å‰ªè§†é¢‘ä¸­çš„é™æ€å¸§ï¼Œåªä¿ç•™è¿åŠ¨ç‰‡æ®µ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s video.mp4                          # è‡ªåŠ¨è£å‰ªï¼Œè¾“å‡º video.trimmed.mp4
  %(prog)s video.mp4 -o output.mp4            # æŒ‡å®šè¾“å‡ºè·¯å¾„
  %(prog)s video.mp4 --threshold 8.0          # æ‰‹åŠ¨è®¾ç½®é˜ˆå€¼
  %(prog)s video.mp4 --buffer 0.5             # å¢åŠ ç¼“å†²æ—¶é—´
  %(prog)s video.mp4 --quiet                  # é™é»˜æ¨¡å¼
        """
    )

    parser.add_argument(
        "input",
        help="è¾“å…¥è§†é¢‘è·¯å¾„"
    )
    parser.add_argument(
        "-o", "--output",
        help="è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆé»˜è®¤: input.trimmed.mp4ï¼‰"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        help="å¸§å·®å¼‚é˜ˆå€¼ 0-255ï¼ˆé»˜è®¤: è‡ªåŠ¨æ£€æµ‹ï¼‰"
    )
    parser.add_argument(
        "--min-duration",
        type=float,
        default=0.3,
        help="æœ€å°è¿åŠ¨æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤: 0.3ï¼‰"
    )
    parser.add_argument(
        "--merge-gap",
        type=float,
        default=0.3,
        help="åˆå¹¶é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤: 0.3ï¼‰"
    )
    parser.add_argument(
        "--buffer",
        type=float,
        default=0.2,
        help="ç¼“å†²æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 0.2ï¼‰"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼ˆä¸æ‰“å°æ—¥å¿—ï¼‰"
    )

    args = parser.parse_args()

    try:
        output = trim_video(
            input_path=args.input,
            output_path=args.output,
            threshold=args.threshold,
            min_motion_duration=args.min_duration,
            merge_gap=args.merge_gap,
            buffer=args.buffer,
            verbose=not args.quiet
        )

        if not args.quiet:
            print(f"\nâœ… å®Œæˆ: {output}")

        sys.exit(0)

    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶ä¸å­˜åœ¨: {str(e)}", file=sys.stderr)
        sys.exit(1)
    except ValueError as e:
        print(f"\nâŒ å‚æ•°é”™è¯¯: {str(e)}", file=sys.stderr)
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ FFmpeg é”™è¯¯: {e.stderr.decode() if e.stderr else str(e)}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)

