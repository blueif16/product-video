#!/usr/bin/env python3
"""
é‡æ–°ç”ŸæˆéŸ³ä¹å¹¶æ··åˆåˆ°å·²æ¸²æŸ“çš„è§†é¢‘

ç”¨æ³•:
    python scripts/regenerate_music_and_mux.py <video_project_id>

ç¤ºä¾‹:
    python scripts/regenerate_music_and_mux.py a8beb3c2-01a6-4480-b37f-30fdc56c4e7b
"""
import sys
import os
import json
import subprocess
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))


def load_env_variable(key: str) -> str:
    """ä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡"""
    # å…ˆå°è¯•ç³»ç»Ÿç¯å¢ƒå˜é‡
    value = os.getenv(key)
    if value:
        return value

    # è¯»å– .env æ–‡ä»¶
    env_path = project_root / ".env"
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    env_key, env_value = line.split('=', 1)
                    if env_key.strip() == key:
                        # ç§»é™¤å¼•å·
                        return env_value.strip().strip('"').strip("'")
    return None


def analyze_timeline_for_music_simple(video_project_id: str) -> dict:
    """ç®€åŒ–ç‰ˆçš„æ—¶é—´çº¿åˆ†æï¼Œç›´æ¥ä» video_spec è¯»å–"""
    spec_path = project_root / "assets" / "specs" / f"{video_project_id}.json"

    with open(spec_path, "r") as f:
        spec = json.load(f)

    meta = spec.get("meta", {})
    clips = spec.get("clips", [])
    fps = meta.get("fps", 30)
    total_frames = meta.get("durationFrames", 0)
    total_duration_s = total_frames / fps

    # ç®€å•çš„ hit points æå–
    hit_points = []
    for clip in clips:
        start_frame = clip.get("startFrame", 0)
        duration_frames = clip.get("durationFrames", 0)
        start_s = start_frame / fps
        duration_s = duration_frames / fps

        # æå–æ–‡æœ¬å†…å®¹
        layers = clip.get("layers", [])
        text_content = ""
        for layer in layers:
            if layer.get("type") == "text":
                text_content = layer.get("content", "")
                break

        # ç®€å•çš„èƒ½é‡æ¨æ–­
        energy = "medium"
        if start_s == 0 or start_s >= total_duration_s - 2:
            energy = "impact"
        elif duration_s < 1.0:
            energy = "high"

        hit_points.append({
            "time_s": start_s,
            "duration_s": duration_s,
            "energy": energy,
            "description": text_content[:50],
        })

    # ç®€å•çš„ sections åˆ†ç»„
    sections = []
    section_duration_ms = int(total_duration_s * 1000 / 5)  # åˆ†æˆ5æ®µ
    for i in range(5):
        sections.append({
            "name": f"Section {i+1}",
            "duration_ms": section_duration_ms,
            "energy": "medium",
        })

    # ç”ŸæˆåŸºç¡€ composition plan
    composition_plan = {
        "positive_global_styles": ["modern", "electronic", "upbeat", "tech"],
        "negative_global_styles": ["sad", "dark", "aggressive"],
        "sections": [
            {
                "section_name": s["name"],
                "duration_ms": s["duration_ms"],
                "positive_local_styles": ["bright", "clean"],
                "negative_local_styles": ["muddy"],
                "lines": []
            }
            for s in sections
        ]
    }

    # åˆå¹¶çŸ­ sectionsï¼ˆElevenLabs è¦æ±‚æ¯ä¸ª section >= 3000msï¼‰
    MIN_SECTION_DURATION = 3000
    merged_sections = []
    buffer = None

    for section in composition_plan["sections"]:
        if buffer:
            section = {
                "section_name": f"{buffer['section_name']} + {section['section_name']}",
                "duration_ms": buffer["duration_ms"] + section["duration_ms"],
                "positive_local_styles": buffer["positive_local_styles"] + section["positive_local_styles"],
                "negative_local_styles": buffer["negative_local_styles"] + section["negative_local_styles"],
                "lines": []
            }
            buffer = None

        if section["duration_ms"] < MIN_SECTION_DURATION:
            buffer = section
        else:
            merged_sections.append(section)

    if buffer:
        if merged_sections:
            last = merged_sections[-1]
            merged_sections[-1] = {
                "section_name": f"{last['section_name']} + {buffer['section_name']}",
                "duration_ms": last["duration_ms"] + buffer["duration_ms"],
                "positive_local_styles": last["positive_local_styles"] + buffer["positive_local_styles"],
                "negative_local_styles": last["negative_local_styles"] + buffer["negative_local_styles"],
                "lines": []
            }
        else:
            merged_sections.append(buffer)

    composition_plan["sections"] = merged_sections

    return {
        "total_duration_ms": int(total_duration_s * 1000),
        "clip_density": len(clips) / total_duration_s,
        "energy_curve": "medium",
        "recommended_tempo": 115,
        "hit_points": hit_points,
        "sections": sections,
        "composition_plan": composition_plan,
    }


def generate_music_with_elevenlabs(composition_plan: dict, output_path: Path) -> bool:
    """ä½¿ç”¨ ElevenLabs ç”ŸæˆéŸ³ä¹"""
    try:
        from elevenlabs.client import ElevenLabs

        api_key = load_env_variable("ELEVENLABS_API_KEY")
        if not api_key:
            print("   âŒ ç¼ºå°‘ ELEVENLABS_API_KEY ç¯å¢ƒå˜é‡")
            return False

        print("   ğŸ¹ ä½¿ç”¨ ElevenLabs ç”ŸæˆéŸ³é¢‘...")
        client = ElevenLabs(api_key=api_key)

        track = client.music.compose(
            composition_plan=composition_plan,
            respect_sections_durations=True,
        )

        with open(output_path, "wb") as f:
            for chunk in track:
                f.write(chunk)

        print(f"   âœ“ éŸ³ä¹ç”ŸæˆæˆåŠŸ: {output_path}")
        return True
    except Exception as e:
        print(f"   âŒ éŸ³ä¹ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def mux_audio_video_ffmpeg(video_path: Path, audio_path: Path, output_path: Path) -> bool:
    """ä½¿ç”¨ FFmpeg æ··åˆéŸ³è§†é¢‘"""
    cmd = [
        "ffmpeg", "-y",
        "-i", str(video_path),
        "-i", str(audio_path),
        "-map", "0:v:0",
        "-map", "1:a:0",
        "-c:v", "copy",
        "-c:a", "aac",
        "-b:a", "192k",
        "-shortest",
        str(output_path)
    ]

    try:
        print("   ğŸ“€ è¿è¡Œ FFmpeg...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

        if result.returncode == 0:
            print(f"   âœ“ æ··åˆæˆåŠŸ: {output_path}")
            return True
        else:
            print(f"   âŒ FFmpeg é”™è¯¯: {result.stderr[:500]}")
            return False
    except Exception as e:
        print(f"   âŒ æ··åˆå¤±è´¥: {e}")
        return False


def main():
    if len(sys.argv) < 2:
        print("âŒ ç¼ºå°‘å‚æ•°: video_project_id")
        print(f"\nç”¨æ³•: python {sys.argv[0]} <video_project_id>")
        sys.exit(1)

    video_project_id = sys.argv[1]

    print(f"\n{'='*60}")
    print(f"é‡æ–°ç”ŸæˆéŸ³ä¹å¹¶æ··åˆåˆ°è§†é¢‘")
    print(f"{'='*60}")
    print(f"Video Project ID: {video_project_id}\n")

    # æ£€æŸ¥æ–‡ä»¶
    spec_path = project_root / "assets" / "specs" / f"{video_project_id}.json"
    render_path = project_root / "assets" / "renders" / f"{video_project_id}.mp4"

    if not spec_path.exists():
        print(f"âŒ VideoSpec ä¸å­˜åœ¨: {spec_path}")
        sys.exit(1)
    if not render_path.exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {render_path}")
        sys.exit(1)

    print(f"âœ“ VideoSpec: {spec_path}")
    print(f"âœ“ æ¸²æŸ“è§†é¢‘: {render_path}")

    # æ­¥éª¤ 1: åˆ†ææ—¶é—´çº¿
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 1: åˆ†æè§†é¢‘æ—¶é—´çº¿")
    print(f"{'='*60}")

    try:
        music_analysis = analyze_timeline_for_music_simple(video_project_id)
        print(f"   âœ“ æ€»æ—¶é•¿: {music_analysis['total_duration_ms']/1000:.1f}s")
        print(f"   âœ“ ç‰‡æ®µæ•°: {len(music_analysis['hit_points'])}")
        print(f"   âœ“ éŸ³ä¹æ®µè½: {len(music_analysis['sections'])}")
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        sys.exit(1)

    # æ­¥éª¤ 2: ç”ŸæˆéŸ³ä¹
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 2: ç”ŸæˆèƒŒæ™¯éŸ³ä¹")
    print(f"{'='*60}")

    audio_dir = project_root / "assets" / "audio"
    audio_dir.mkdir(parents=True, exist_ok=True)
    audio_path = audio_dir / f"{video_project_id}_bgm.mp3"

    if not generate_music_with_elevenlabs(music_analysis["composition_plan"], audio_path):
        sys.exit(1)

    # æ­¥éª¤ 3: æ··åˆéŸ³è§†é¢‘
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 3: æ··åˆéŸ³é¢‘å’Œè§†é¢‘")
    print(f"{'='*60}")

    output_path = render_path.parent / f"{render_path.stem}_with_audio{render_path.suffix}"

    if not mux_audio_video_ffmpeg(render_path, audio_path, output_path):
        sys.exit(1)

    print(f"\n{'='*60}")
    print("âœ… å®Œæˆ!")
    print(f"{'='*60}")
    print(f"\nğŸ¬ æœ€ç»ˆè§†é¢‘ (å¸¦éŸ³ä¹): {output_path}\n")


if __name__ == "__main__":
    main()
